{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jkc1-4/python-for-micro/blob/main/pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "d3Vh5SUf0Ktb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow tensorflow-gpu matplotlib tensorflow-datasets ipywidgets\n"
      ],
      "metadata": {
        "id": "F93QHlFl0YHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "DE81Q1DD2V_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-datasets"
      ],
      "metadata": {
        "id": "AJO2LL-r3_sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "id": "QWfQvM0n4GUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "3m1HLPQ_4MYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "WdxTxyQ_4W_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu  in gpus:\n",
        "  tf.config.experimental.set_memory_growth(gpu,True)\n",
        ""
      ],
      "metadata": {
        "id": "hP8H-k7u4jY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus"
      ],
      "metadata": {
        "id": "2Rc5cbUY8lzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bring the tensorlfow dATAset and fashin mnist\n",
        "import tensorflow_datasets as tfds\n",
        "#bring the matplotlib for visual stuff\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "c3tTjkj28m3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tfds.load('fashion_mnist',split='train')"
      ],
      "metadata": {
        "id": "A7JFERUG9VBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "JLsnO9us9hM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "QpSkdZuU94DP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4XslUiqG-CUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. viz the dataset and build dataset\n"
      ],
      "metadata": {
        "id": "SYuFeCdJ-iDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#do some data transformastion\n",
        "import numpy as np\n",
        "#setup connection aka iterator so that we can iterated and bring back the next item in the list just like as linked list in java\n",
        "dataiterator = ds.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "fG4sh05N-oNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we can the call the .next() to bring tha array of datasets in list using\n",
        "#getting data out of a pipeline\n",
        "dataiterator.next()"
      ],
      "metadata": {
        "id": "DymW1h05_bAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the subplot formation using matplotlib and i want to total subplot or fig to 20x20 size\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "#loop for 4 times and get images\n",
        "for idx in range(4):\n",
        "  #grab an image and label\n",
        "  sample = dataiterator.next()\n",
        "  #plot the image using the specific subplot/axis where ax is axis , squeeze means to sqeeze the co-ordinates for viz\n",
        "  ax[idx].imshow(np.squeeze(sample['image']))\n",
        "  #title is optional , its for the top numbering or name of images\n",
        "  ax[idx].title.set_text(sample['label'])"
      ],
      "metadata": {
        "id": "f-Tb0GDz_tUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale and return the images only\n",
        "def scale_images(data):\n",
        "  image=data['image']\n",
        "  return image/255"
      ],
      "metadata": {
        "id": "QbjiKiwSBthm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reloading the dataset\n",
        "ds = tfds.load('fashion_mnist',split='train')\n",
        "#running the dataset through the scale image preprocessing step\n",
        "ds = ds.map(scale_images)\n",
        "#cachee the dataset for that batch\n",
        "ds= ds.cache()\n",
        "#shuffle it up\n",
        "ds  = ds.shuffle(60000)\n",
        "#batch into 128 images per sample\n",
        "ds = ds.batch(128)\n",
        "#reduce the likelyhood of bottlenecking\n",
        "ds = ds.prefetch(64)\n",
        "\n",
        "ds.as_numpy_iterator().next().shape\n"
      ],
      "metadata": {
        "id": "J8_-_plAIY7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.build the neural network\n",
        "*   importing the model components\n",
        "*   build the generator\n",
        "*   build the discriminator\n"
      ],
      "metadata": {
        "id": "X9l262JtJYOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bringing in the sequential api for the generator and discriminator\n",
        "from tensorflow.keras.models import Sequential\n",
        "#bringin in the layers for the neural networks\n",
        "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Reshape,LeakyReLU,Dropout,UpSampling2D"
      ],
      "metadata": {
        "id": "wufFBybyLEkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "  model = Sequential()\n",
        "\n",
        "#here we r specifing what our input layer is going to be ,i.e, a dense fully connect layer, 7,7,128 units means the 128 image input is going to convert to 7*7*128 spacial quality\n",
        "# in conditional GAN we can specify what image we want to generate but here it is generating random images from sample population\n",
        "  model.add(Dense(7*7*128, input_dim=128))\n",
        "  #this just means y=0.2 how thw graph is slope\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  #now we convert the dense layer into the begining of a image of size 7*7*128 which inventually will be 28*28*1\n",
        "  model.add(Reshape((7,7,128)))\n",
        "\n",
        "  #upsampling block 1\n",
        "  model.add(UpSampling2D()) # this doubles the size of output\n",
        "  model.add(Conv2D(128,5, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #upsampling block 2\n",
        "  model.add(UpSampling2D()) # this doubles the size of output\n",
        "  model.add(Conv2D(128,5, padding='same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #convolutional block 1\n",
        "  model.add(Conv2D(128,4 , padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #con block 2\n",
        "  model.add(Conv2D(128,4,padding = 'same'))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "\n",
        "  #Conc layer to get to one channel\n",
        "  model.add(Conv2D(1,4,padding='same' ,activation = 'sigmoid'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "qnt_2O1mO95y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "2Ja00tCyQjM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = generator.predict(np.random.randn(4,128,1))\n",
        "img.shape"
      ],
      "metadata": {
        "id": "qXFGAsuiQvQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the subplot formation using matplotlib and i want to total subplot or fig to 20x20 size\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "#loop for 4 times and get images\n",
        "for idx ,img in enumerate(img): #this to get the index in image\n",
        "\n",
        "  #plot the image using the specific subplot/axis where ax is axis , squeeze means to sqeeze the co-ordinates for viz\n",
        "  ax[idx].imshow(np.squeeze(img))\n",
        "  #title is optional , its for the top numbering or name of images\n",
        "  ax[idx].title.set_text(idx)"
      ],
      "metadata": {
        "id": "twdFM6PIWqY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "  model = Sequential()\n",
        "\n",
        "  #First conv block\n",
        "  model.add(Conv2D(32,5,input_shape=(28,28,1)))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))#0.4 is strength of the dropout\n",
        "\n",
        "  #second conv block\n",
        "  model.add(Conv2D(64,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #thrid conv block\n",
        "  model.add(Conv2D(128,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #forth conv block\n",
        "  model.add(Conv2D(256,5))\n",
        "  model.add(LeakyReLU(0.2))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  #Flatten then passa thru dense layer\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1,activation='sigmoid'))#1 represent false img\n",
        "  return model"
      ],
      "metadata": {
        "id": "x94opb8VXTgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = build_discriminator()\n",
        "discriminator.summary()\n"
      ],
      "metadata": {
        "id": "o28EYM1dYitZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.shape"
      ],
      "metadata": {
        "id": "hH0ZausTcDf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.predict(img)"
      ],
      "metadata": {
        "id": "op7cUDZAeBM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct Training loop**\n",
        "\n",
        "1.   setup loses and optimizers"
      ],
      "metadata": {
        "id": "0fLXq5GRiJ2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adam is going to be the optimizers for both\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# binary cross entropy is goinhg to be the loss for both\n",
        "from tensorflow.keras.losses import BinaryCrossentropy"
      ],
      "metadata": {
        "id": "f4ppUpTcidNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_opt=Adam(learning_rate=0.0001)\n",
        "d_opt=Adam(learning_rate=0.00001)\n",
        "g_loss=BinaryCrossentropy()\n",
        "d_loss=BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "0s-nb0-2i97v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.2 Build Subclass Model**"
      ],
      "metadata": {
        "id": "FcAmZC9SkPru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the base model class to subclass\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "lsqjyJWtkWUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.normal((6,128,1))"
      ],
      "metadata": {
        "id": "GwLX5cS4pPVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionGAN(Model):\n",
        "  def __init__(self, generator, discriminator, *args, **kwargs):\n",
        "    #pass thru *args kwargs to base class\n",
        "    super().__init__(*args,**kwargs)\n",
        "\n",
        "    #create attributes  for gen and discr\n",
        "    self.generator = generator\n",
        "    self.discriminator = discriminator\n",
        "\n",
        "\n",
        "  def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
        "    #compile the base class\n",
        "    super().compile(*args, **kwargs)\n",
        "\n",
        "  #create attributes for losses and optimizers\n",
        "    self.g_opt=g_opt\n",
        "    self.d_opt=d_opt\n",
        "    self.g_loss= g_loss\n",
        "    self.d_loss= d_loss\n",
        "\n",
        "  def train_step(self, batch):\n",
        "    #get the data\n",
        "    real_images = batch\n",
        "    fake_images = self.generator(tf.random.normal((128,128,1)),training=False)\n",
        "\n",
        "    #Train the discriminator\n",
        "    with tf.GradientTape() as d_Tape:\n",
        "\n",
        "      #Pass the real and fake image to the discriminator model\n",
        "      yhat_real= self.discriminator(real_images, training=True)\n",
        "      yhat_fake = self.discriminator(fake_images, training=True)\n",
        "      yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
        "\n",
        "\n",
        "      #Create labels for the real and fake images\n",
        "      y_realfake = tf.concat([tf.zeros_like(yhat_real),tf.ones_like(yhat_fake)], axis=0)\n",
        "\n",
        "      #Add some noise to the TRUE outputs\n",
        "      noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
        "      noise_fake = 0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
        "      y_realfake = tf.concat([noise_real,noise_fake] , axis=0)\n",
        "\n",
        "      #Calculate the loss\n",
        "      total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
        "\n",
        "    #Apply the backpropogation -- this is how neural network learn\n",
        "    dgrad = d_Tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
        "    self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
        "\n",
        "  #def test_step(self):\n",
        "\n",
        "\n",
        "    #TRAIN THE GENERATOR\n",
        "    with tf.GradientTape() as g_tape:\n",
        "\n",
        "      #generate some new images\n",
        "      gen_images = self.generator(tf.random.normal((128,128,1)),training=True)\n",
        "\n",
        "      #create predicted labels\n",
        "      predicted_labels = self.discriminator(gen_images, training=False)\n",
        "\n",
        "      #calculate loss\n",
        "      total_g_loss = self.g_loss(tf.zeros_like(predicted_labels),predicted_labels)\n",
        "\n",
        "    #apply back-prop\n",
        "    ggrad= g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
        "    self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
        "\n",
        "    return {\"d_loss\":total_d_loss, \"g_loss\":total_g_loss}\n"
      ],
      "metadata": {
        "id": "FzotqGNykrj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create instance of subclasses model above\n",
        "fashgan = FashionGAN(generator,discriminator)\n"
      ],
      "metadata": {
        "id": "tohRttmSxm60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashgan.compile(g_opt,d_opt,g_loss,d_loss)"
      ],
      "metadata": {
        "id": "vFIPJkFox_Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build callback**"
      ],
      "metadata": {
        "id": "f9e8xofkyQ1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #help with photo navigation\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "from tensorflow.keras.callbacks import Callback"
      ],
      "metadata": {
        "id": "CTf_anPByEJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelMonitor(Callback):\n",
        "    def __init__(self, num_img=3, latent_dim=128):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images *= 255\n",
        "        generated_images.numpy()\n",
        "        for i in range(self.num_img):\n",
        "            img = array_to_img(generated_images[i])\n",
        "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
      ],
      "metadata": {
        "id": "8a_qMVw2zYnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist=fashgan.fit(ds,epochs=20,  callbacks=[ModelMonitor()])\n",
        "#recommended 2000 epochs  callbacks=[ModelMonitor()]"
      ],
      "metadata": {
        "id": "5n1kN7NOzdp7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}